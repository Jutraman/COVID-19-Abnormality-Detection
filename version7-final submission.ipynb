{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"version7-final submission.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOa/i1HJhItR1uQIeVkFn33"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BmokXlpekSyn"},"source":["# Final submission\n","- This file includes the raw data processing and all experiment steps, like data processing, feature extraction, and models combination.\n","\n","- The expeiment is set on the Google Colab, which means all the hardware is provided by Google standard device: TPU and GPU. \n","\n","- The whole expriment is diveded into several parts, according to the logical definition and required performance. For example, the enhancement of images via fuzzy logic before DL is finished via 7 steps, because the GPU performance is not enough to process 6334 pictures in one step.\n","\n","- This version is the no.7, if some confusion accured, please check former version, which tell more details about my project."]},{"cell_type":"markdown","metadata":{"id":"qTL51S7hmZLE"},"source":["# Data Structure\n","The workshop dir is on the Google Drive, the root path is \"/content/drive/MyDrive/CovidDectection\"\n","\n","- CovidDetection\n","  - siim-covid19-detection: raw data dir, which is downloaded from Kaggle\n","    - train\n","    - test\n","    - sample_submission.csv\n","    - train_image_level.csv\n","    - train_study_level.csv\n","  - dataset: data dir\n","    - tmp: processed data dir, 256*256, .jpg\n","    - fctmp: fuzzy enhanced data dir based on tmp, 256*256, .jpg\n","    - fgtmp: fuzzy enhanced data dir based on tmp, 256*256, .jpg\n","    - info: the dir for info summary, which is processed before the model running and easy for using by every version\n","  - version_n\n","    - dataset: which is copied from dir, \"dataset\", and the data is ready for this experiment version.\n","      - images\n","        - train\n","        - val\n","      - labels\n","        - train\n","        - val\n","      - others: like yolo, which is dir for Yolo algorithmn.\n","  - submission\n","    - to be continued."]},{"cell_type":"markdown","metadata":{"id":"MFQNAIrxrqws"},"source":["# Submission file \n","- Data processing\n","- Feature extraction\n","- Model \n","  - fuzzy enhancement (optional)\n","  - YOLO v5/3\n","  - Choquet Intergral\n","- Metrics\n","  - IoU\n","  - mAP\n","  - mAP@0.5-0.95"]},{"cell_type":"markdown","metadata":{"id":"kS72Tt_JwE6_"},"source":["# Preparation\n","- to mount Google Drive\n","- to make dirs\n","- to download compitetion dataset\n","- to install required packages\n","- login in Wandb\n","\n","Ready, Go!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-s0sLvqKxQQB","executionInfo":{"status":"ok","timestamp":1632050294886,"user_tz":-60,"elapsed":25748,"user":{"displayName":"Jutraman Coder","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtCvz3vW15nCDPF_G-E7wS3C1k_yCtpuGAxWh4=s64","userId":"14833591816752276710"}},"outputId":"4c7ed0ef-3915-4086-ab25-9237d04bde86"},"source":["# to mount Google Drive\n","# The root path is \"/content/drive/\"\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ndpLLfbyPRZ","executionInfo":{"status":"ok","timestamp":1632050419691,"user_tz":-60,"elapsed":245,"user":{"displayName":"Jutraman Coder","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtCvz3vW15nCDPF_G-E7wS3C1k_yCtpuGAxWh4=s64","userId":"14833591816752276710"}},"outputId":"36fed728-8843-4675-e27f-fffda86e80aa"},"source":["!python -V"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.7.12\n"]}]},{"cell_type":"code","metadata":{"id":"Gt8N0ZiiySq1"},"source":["!pip install matplotlib\n","!pip install numpy\n","!pip install opencv-python\n","!pip install pillow\n","!pip install pyyaml\n","!pip install scipy\n","!pip install torch\n","!pip install torchvision\n","!pip install tqdm\n","!pip install tensorboard\n","!pip install wandb\n","!pip install seaborn\n","!pip install pandas\n","!pip install coremltools\n","!pip install onnx\n","!pip install onnx-simlifier\n","!pip install scikit-learn\n","!pip install tensorflow\n","!pip install tensorflowjs\n","!pip install thop\n","!pip install pydicom\n","!pip install pylibjpeg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3FumlZTwxVJE","executionInfo":{"status":"ok","timestamp":1632051078643,"user_tz":-60,"elapsed":188,"user":{"displayName":"Jutraman Coder","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtCvz3vW15nCDPF_G-E7wS3C1k_yCtpuGAxWh4=s64","userId":"14833591816752276710"}},"outputId":"67d2f845-67e2-44aa-b159-d5e3eaa36253"},"source":["# to make workshop dirs\n","\n","import os\n","print(\"Created folder structure\")\n","os.makedirs('/content/drive/MyDrive/CovidDetection', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/dataset', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/dataset/tmp', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/dataset/fctmp', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/dataset/fgtmp', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/dataset/info', exist_ok=True)\n","\n","os.makedirs('/content/drive/MyDrive/CovidDetection/submission', exist_ok=True)\n","#os.makedirs('/content/drive/MyDrive/CovidDetection/version_n', exist_ok=True)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Created folder structure\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tNjeD9e04wg","executionInfo":{"status":"ok","timestamp":1632051460823,"user_tz":-60,"elapsed":194,"user":{"displayName":"Jutraman Coder","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtCvz3vW15nCDPF_G-E7wS3C1k_yCtpuGAxWh4=s64","userId":"14833591816752276710"}},"outputId":"ef929e64-b316-4384-91b3-7ea035796931"},"source":["# to download the raw dataset from Kaggle\n","\n","%cd /content/drive/MyDrive/CovidDetection/\n","!ls\n","## the command to download is shown next line, and I have download it, so I commented it out.\n","#!kaggle competitions download -c siim-covid19-detection\n","#!cp /content/drive/MyDrive/CovidDetection/siim-covid19-detection/train_image_level.csv /content/drive/MyDrive/CovidDetection/dataset/info/train_image_level.csv\n","#!cp /content/drive/MyDrive/CovidDetection/siim-covid19-detection/train_study_level.csv /content/drive/MyDrive/CovidDetection/dataset/info/train_study_level.csv"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CovidDetection\n","dataset  submission\n"]}]},{"cell_type":"code","metadata":{"id":"nMeMDy7n2Qua"},"source":["import wandb\n","wandb.login()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o6TJNnTe2XTz"},"source":["import tensorboard as tb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wp5ccw9evyxC"},"source":["# Part 1 Data processing & Feature extraction"]},{"cell_type":"markdown","metadata":{"id":"eAm_976Ov3PM"},"source":["## Part 1-1 Dicom to JPG\n","Dicom "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IpxYn7fVmV3J","executionInfo":{"status":"ok","timestamp":1632051817140,"user_tz":-60,"elapsed":528,"user":{"displayName":"Jutraman Coder","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtCvz3vW15nCDPF_G-E7wS3C1k_yCtpuGAxWh4=s64","userId":"14833591816752276710"}},"outputId":"ec304e63-e130-445b-818f-c9ee3729353b"},"source":["%cd /content/drive/MyDrive/CovidDetection/\n","!ls"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CovidDetection\n","dataset  siim-covid19-detection  submission\n"]}]},{"cell_type":"code","metadata":{"id":"YZbKS_rA28Hq"},"source":["import os\n","\n","from PIL import Image\n","import pandas as pd\n","from tqdm.auto import tqdm\n","import pylibjpeg\n","import numpy as np\n","import pydicom\n","from pydicom.pixel_data_handlers.util import apply_voi_lut"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yxLq8bK23yL6"},"source":["def read_xray(path, voi_lut = True, fix_monochrome = True):\n","    dicom = pydicom.read_file(path)\n","    \n","    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n","    if voi_lut:\n","        data = apply_voi_lut(dicom.pixel_array, dicom)\n","    else:\n","        data = dicom.pixel_array\n","               \n","    # depending on this value, X-ray may look inverted - fix that:\n","    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n","        data = np.amax(data) - data\n","        \n","    data = data - np.min(data)\n","    data = data / np.max(data)\n","    data = (data * 255).astype(np.uint8)\n","        \n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8th46nt24IoQ"},"source":["def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n","    im = Image.fromarray(array)\n","    \n","    if keep_ratio:\n","        im.thumbnail((size, size), resample)\n","    else:\n","        im = im.resize((size, size), resample)\n","    \n","    return im"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"djoLwri94M0f"},"source":["image_id = []\n","dim0 = []\n","dim1 = []\n","splits = []\n","\n","for split in ['train', 'test']:\n","    save_dir = f'/content/drive/MyDrive/CovidDetection/dataset/tmp/{split}/'\n","\n","    os.makedirs(save_dir, exist_ok=True)\n","    \n","    for dirname, _, filenames in tqdm(os.walk(f'/content/drive/MyDrive/CovidDetection/siim-covid19-detection/{split}')):\n","        for file in filenames:\n","            # set keep_ratio=True to have original aspect ratio\n","            xray = read_xray(os.path.join(dirname, file))\n","            im = resize(xray, size=256)  \n","            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))\n","\n","            image_id.append(file.replace('.dcm', ''))\n","            dim0.append(xray.shape[0])\n","            dim1.append(xray.shape[1])\n","            splits.append(split)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p7mGdpWZ59r1"},"source":["df = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})\n","df.to_csv('/content/drive/MyDrive/CovidDetection/info/meta.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_l5q3kg25azk"},"source":["## Part 1-2 \n","- Raw file:\n","  - train_image_level.csv\n","  - train_study_level.csv\n","- Final file:\n","  - info_summary.csv\n","- Other files\n","  - They are all temp files."]},{"cell_type":"code","metadata":{"id":"51qbWCEt5jRq","executionInfo":{"status":"ok","timestamp":1632052655450,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jutraman Coder","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtCvz3vW15nCDPF_G-E7wS3C1k_yCtpuGAxWh4=s64","userId":"14833591816752276710"}}},"source":["import pandas as pd\n","import numpy as np\n","import ast"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGAps8Ve6zKn","executionInfo":{"status":"ok","timestamp":1632052687432,"user_tz":-60,"elapsed":525,"user":{"displayName":"Jutraman Coder","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhtCvz3vW15nCDPF_G-E7wS3C1k_yCtpuGAxWh4=s64","userId":"14833591816752276710"}},"outputId":"0b0c05f4-ea35-4e88-b625-060faf5597e3"},"source":["%cd /content/drive/MyDrive/CovidDetection/dataset/info\n","!ls"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CovidDetection/dataset/info\n"]}]},{"cell_type":"code","metadata":{"id":"cT231yhM666R"},"source":["meta=pd.read_csv(\"meta.csv\")\n","meta_train=meta.loc[meta.split=='train',['image_id','dim1','dim0']]\n","meta_train.columns=['image_id','width','height']\n","meta_test=meta.loc[meta.split=='test',['image_id','dim1','dim0']]\n","meta_test.columns=['image_id','width','height']\n","meta_train.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbQaa9PF7Emk"},"source":["train_image_level=pd.read_csv(\"train_image_level.csv\")\n","train_image_level[\"id\"] = train_image_level[\"id\"].map(lambda x : x.replace(\"_image\",\"\"))\n","train_image_level.rename(columns={'id':\"image_id\",'label':\"image_label\",\"StudyInstanceUID\":\"study_id\"},inplace=True)\n","train_image_level.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmlrOqrO7Isz"},"source":["rain_study_level=pd.read_csv(\"train_study_level.csv\")\n","classes_dict = {\n","    0 : \"Negative for Pneumonia\",\n","    1  : \"Typical Appearance\",\n","    2  : \"Indeterminate Appearance\",\n","    3  : \"Atypical Appearance\"\n","}\n","\n","# Making one-hot of study_level labels and removing other 4 class columns\n","train_study_level[\"one_hot\"] = train_study_level.apply(lambda x : np.array([x[\"Negative for Pneumonia\"],\n","                                                        x[\"Typical Appearance\"],\n","                                                        x[\"Indeterminate Appearance\"],\n","                                                        x[\"Atypical Appearance\"]]),axis=1)\n","\n","train_study_level[\"pneumonia\"] = train_study_level[\"one_hot\"].map(lambda x : classes_dict[np.argmax(x)])\n","train_study_level[\"pneumonia_class\"] = train_study_level[\"one_hot\"].map(lambda x : np.argmax(x))\n","train_study_level = train_study_level.drop([\"Negative for Pneumonia\",\"Typical Appearance\",\"Indeterminate Appearance\",\"Atypical Appearance\",\"one_hot\"],axis=1)\n","train_study_level[\"id\"] = train_study_level[\"id\"].map(lambda x : x.replace(\"_study\",\"\"))\n","train_study_level.rename(columns={\"id\" : \"study_id\"},inplace=True)\n","train_study_level.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezJEkSLq7LLh"},"source":["train_info = pd.merge(train_image_level,train_study_level,on = \"study_id\") # Merging study_df and image_df\n","\n","train_info = pd.merge(train_info,meta_train,on = \"image_id\") # Merging to meta_train for height,width\n","\n","# Filling NaN values \n","train_info[\"boxes\"].fillna(\"[{'x':0,'y':0,'width':1,'height':1}]\",inplace=True)\n","temp = train_info # for going through the data\n","train_info[\"boxes\"] = train_info[\"boxes\"].map(lambda x : ast.literal_eval(x))\n","\n","\n","columns = [\"image_id\",\"study_id\",\"pneumonia\",\"pneumonia_class\",\"height\",\"width\",\"boxes\",\"image_label\"] # for proper order\n","train_info = train_info[columns]\n","\n","\n","train_info.to_csv(\"/content/drive/MyDrive/CovidDetection/dataset/info/train_info.csv\",index=False)\n","train_info.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pyte7atS7TWg"},"source":["meta_train.to_csv(\"/content/drive/MyDrive/CovidDetection/dataset/info/meta_train.csv\",index=False)\n","meta_test.to_csv(\"/content/drive/MyDrive/CovidDetection/dataset/info/meta_test.csv\",index=False)\n","train_image_level.to_csv(\"/content/drive/MyDrive/CovidDetection/dataset/info/train_image_level_temp.csv\",index=False)\n","train_study_level.to_csv(\"/content/drive/MyDrive/CovidDetection/dataset/info/train_study_level_temp.csv\",index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"16Sq4_TH7gKr"},"source":["# Get image path from image_id\n","def get_path(image_id):\n","    path = tf.io.gfile.glob(TRAIN_PATH + f\"*{image_id}.jpg\")[0]\n","    return path\n","\n","image_dict = {\n","    \"opacity\" : 1,\n","    \"none\" : 0\n","}\n","df = pd.read_csv(\"/content/drive/MyDrive/CovidDetection/dataset/info/train_info.csv\")\n","\n","df[\"image_label\"] = df[\"image_label\"].map(lambda x : x.split(\" \")[0])\n","df[\"image_label_id\"] = df[\"image_label\"].map(lambda x  : image_dict[x])\n","df[\"filepath\"] = df[\"image_id\"].map(get_path)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6EICJD28P-u"},"source":["train_df,val_df = train_test_split(df,\n","                                    test_size=0.2,\n","                                    random_state = SEED,\n","                                    stratify = df.image_label.values\n","                                    )\n","\n","train_df.loc[:,\"data\"] = \"train\"\n","val_df.loc[:,\"data\"] = \"val\"\n","df = pd.concat([train_df, val_df]).reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8pKiX9s-GtP"},"source":["train_image_level=pd.read_csv('/content/drive/MyDrive/CovidDetection/dataset/info/train_image_level.csv')\n","# Modify values in the id column\n","train_image_level['image_id'] = train_image_level.apply(lambda row: row.id.split('_')[0], axis=1)\n","# Get image level labels\n","train_image_level['image_level'] = train_image_level.apply(lambda row: row.label.split(' ')[0], axis=1)\n","train_image_level.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHEV_Rzi-Jha"},"source":["df = df.merge(train_image_level, on='image_id',how=\"left\")\n","df.to_csv(\"/content/drive/MyDrive/CovidDetection/dataset/info/train_summary.csv\")\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vf-Bk41t-VvY"},"source":["info=pd.read_csv(\"train_summary.csv\")\n","info[\"fgfp\"]=info.apply(lambda x:x.filepath.replace('tmp','fgtmp'),axis=1)\n","info[\"fcfp\"]=info.apply(lambda x:x.filepath.replace('tmp','fctmp'),axis=1)\n","info.to_csv(\"info_summary.csv\")\n","info.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-oV40Keg8ckg"},"source":["# don't forget to change the dir name of tmp: the test comes from raw file, but the YOLO uses the val\n","#!mv /content/drive/MyDrive/CovidDetection/dataset/tmp/test /content/drive/MyDrive/CovidDetection/dataset/tmp/val"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dQOUV5VHAID9"},"source":["# Part 2 Models"]},{"cell_type":"code","metadata":{"id":"1FmX689ewfwB"},"source":["# To confirm the work folder\n","os.makedirs('/content/drive/MyDrive/CovidDetection/submission', exist_ok=True)\n","%cd /content/drive/MyDrive/CovidDetection/Submission\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_FomTTXxVVE"},"source":["# To download the raw YOLOv5 model\n","!git clone https://github.com/ultralytics/yolov5  # clone repo"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3rb_z2UyWZg"},"source":["import torch\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yq5biOPZyhuW"},"source":["# Necessary/extra dependencies. \n","import os\n","import gc\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from shutil import copyfile\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qiWZlAYq7Aa4"},"source":["info = pd.read_csv(\"/content/drive/MyDrive/CovidDetection/dataset/info/info_summary.csv\")\n","print(f'Size of dataset: {len(info[info.data=])}, training images: {len(train_df)}. validation images: {len(val_df)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I241CeBCAfcc"},"source":["## Part 2-1 Exp 1\n","Baseline \n","YOLO v5s"]},{"cell_type":"code","metadata":{"id":"p3HUXyt71lIt"},"source":["os.makedirs('/content/drive/MyDrive/CovidDetection/submission/dataset/baseline/images/train', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/submission/dataset/baseline/images/val', exist_ok=True)\n","\n","os.makedirs('/content/drive/MyDrive/CovidDetection/submission/dataset/baseline/labels/train', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/submission/dataset/baseline/labels/val', exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQq0XZu23EPg"},"source":["# Move the images to relevant split folder.\n","for i in tqdm(range(len(df))):\n","    row = df.iloc[i]\n","    if row.data == 'train':\n","        copyfile(row.filepath, f'/content/drive/MyDrive/CovidDetection/submission/dataset/baseline/images/train/{row.image_id}.jpg')\n","    else:\n","        copyfile(row.filepath, f'/content/drive/MyDrive/CovidDetection/submission/dataset/baseline/images/val/{row.image_id}.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IcXLk-hg_1OK"},"source":["# Create .yaml file \n","import yaml\n","\n","data_yaml = dict(\n","    train = '/content/drive/MyDrive/CovidDetection/submission/dataset/baseline/images/train',\n","    val = '/content/drive/MyDrive/CovidDetection/submission/dataset/baseline/images/val',\n","    nc = 2,\n","    names = ['none', 'opacity']\n",")\n","\n","# Note that I am creating the file in the yolov5/data/ directory.\n","with open('/content/drive/MyDrive/CovidDetection/submission/src/yolo.yaml', 'w') as outfile:\n","    yaml.dump(data_yaml, outfile, default_flow_style=True)\n","    \n","%cat /content/drive/MyDrive/CovidDetection/submission/src/yolo.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CYpwFxN_AimD"},"source":["# Get the raw bounding box by parsing the row value of the label column.\n","\n","def get_bbox(row):\n","    bboxes = []\n","    bbox = []\n","    for i, l in enumerate(row.label.split(' ')):\n","        if (i % 6 == 0) | (i % 6 == 1):\n","            continue\n","        bbox.append(float(l))\n","        if i % 6 == 5:\n","            bboxes.append(bbox)\n","            bbox = []  \n","            \n","    return bboxes\n","\n","# Scale the bounding boxes according to the size of the resized image. \n","def scale_bbox(row, bboxes):\n","    # Get scaling factor\n","    scale_x = IMG_SIZE/row.width\n","    scale_y = IMG_SIZE/row.height\n","    \n","    scaled_bboxes = []\n","    for bbox in bboxes:\n","        x = int(np.round(bbox[0]*scale_x, 4))\n","        y = int(np.round(bbox[1]*scale_y, 4))\n","        x1 = int(np.round(bbox[2]*(scale_x), 4))\n","        y1= int(np.round(bbox[3]*scale_y, 4))\n","\n","        scaled_bboxes.append([x, y, x1, y1]) # xmin, ymin, xmax, ymax\n","        \n","    return scaled_bboxes\n","\n","# Convert the bounding boxes in YOLO format.\n","def get_yolo_format_bbox(img_w, img_h, bboxes):\n","    yolo_boxes = []\n","    for bbox in bboxes:\n","        w = bbox[2] - bbox[0] # xmax - xmin\n","        h = bbox[3] - bbox[1] # ymax - ymin\n","        xc = bbox[0] + int(np.round(w/2)) # xmin + width/2\n","        yc = bbox[1] + int(np.round(h/2)) # ymin + height/2\n","        \n","        yolo_boxes.append([xc/img_w, yc/img_h, w/img_w, h/img_h]) # x_center y_center width height\n","    \n","    return yolo_boxes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-EK6E4KA25-"},"source":["# Prepare the txt files for bounding box\n","for i in tqdm(range(len(info))):\n","    row = info.loc[i]\n","    # Get image id\n","    img_id = row.image_id\n","    # Get split\n","    split = row.data\n","    # Get image-level label\n","    label = row.image_level\n","    \n","    if row.data=='train':\n","        file_name = f'/content/drive/MyDrive/CovidDetection/submission/dataset/labels/train/{row.image_id}.txt'\n","    else:\n","        file_name = f'/content/drive/MyDrive/CovidDetection/submission/dataset/labels/val/{row.image_id}.txt'\n","        \n","    \n","    if label=='opacity':\n","        # Get bboxes\n","        bboxes = get_bbox(row)\n","        # Scale bounding boxes\n","        scale_bboxes = scale_bbox(row, bboxes)\n","        # Format for YOLOv5\n","        yolo_bboxes = get_yolo_format_bbox(IMG_SIZE, IMG_SIZE, scale_bboxes)\n","        \n","        with open(file_name, 'w') as f:\n","            for bbox in yolo_bboxes:\n","                bbox = [1]+bbox\n","                bbox = [str(i) for i in bbox]\n","                bbox = ' '.join(bbox)\n","                f.write(bbox)\n","                f.write('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aok23EVQFnPX"},"source":["TRAIN_PATH = \"/content/drive/MyDrive/CovidDetection/dataset/tmp/train/\"\n","WEIGHT_PATH=\"/content/drive/MyDrive/CovidDetection/submission/yolov5/yolov5s.pt\"\n","IMG_SIZE = 256\n","BATCH_SIZE = 16\n","EPOCHS = 10\n","TEST_PATH = \"/content/drive/MyDrive/siim/tmp/test\"\n","BEST_MODEL_PATH  =\"/content/drive/MyDrive/siim/version3/yolov5/version3/exp/weights/best.pt\"\n","YAML_PATH=\"/content/drive/MyDrive/CovidDetection/submission/src/yolo.yaml\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5nzH6tm1BYkG"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov5/train.py --img {IMG_SIZE} \\\n","                 --batch {BATCH_SIZE} \\\n","                 --epochs {EPOCHS} \\\n","                 --data {YAML_PATH} \\\n","                 --weights {WIGHT_PATH} \\\n","                 --save_period 1\\\n","                 --project submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBDV1_QRBnLR"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov5/detect.py --weights {BEST_MODEL_PATH} \\\n","                  --source {TEST_PATH} \\\n","                  --img 256 \\\n","                  --conf 0.281 \\\n","                  --iou-thres 0.5 \\\n","                  --max-det 3 \\\n","                  --save-txt \\\n","                  --save-conf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q5ftp8n9COkr"},"source":["## Part 2-2 Exp 2\n","YOLOv3"]},{"cell_type":"code","metadata":{"id":"0x3WJXjPCTeo"},"source":["%cd /content/drive/MyDrive/CovidDetection/submission\n","!git clone https://github.com/ultralytics/yolov3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OrFZ8gw9Gbea"},"source":["TRAIN_PATH = \"/content/drive/MyDrive/CovidDetection/dataset/tmp/train/\"\n","WEIGHT_PATH=\"/content/drive/MyDrive/CovidDetection/submission/yolov3/yolov3.pt\"\n","IMG_SIZE = 256\n","BATCH_SIZE = 16\n","EPOCHS = 10\n","TEST_PATH = \"/content/drive/MyDrive/siim/tmp/test\"\n","BEST_MODEL_PATH  =\"/content/drive/MyDrive/siim/version3/yolov5/version3/exp/weights/best.pt\"\n","YAML_PATH=\"/content/drive/MyDrive/CovidDetection/submission/src/yolo.yaml\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hb-bptitCdr1"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov3/train.py --img {IMG_SIZE} \\\n","                 --batch {BATCH_SIZE} \\\n","                 --epochs {EPOCHS} \\\n","                 --data {YAML_PATH} \\\n","                 --weights {WIGHT_PATH} \\\n","                 --save_period 1\\\n","                 --project submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gruDsbYTFbQB"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov3/detect.py --weights {BEST_MODEL_PATH} \\\n","                  --source {TEST_PATH} \\\n","                  --img 256 \\\n","                  --conf 0.281 \\\n","                  --iou-thres 0.5 \\\n","                  --max-det 3 \\\n","                  --save-txt \\\n","                  --save-conf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OpZQ68MPGn-l"},"source":["## Part 2-3 Exp 3\n","YOLOv5x"]},{"cell_type":"code","metadata":{"id":"_9498xJZG1Ai"},"source":["TRAIN_PATH = \"/content/drive/MyDrive/CovidDetection/dataset/tmp/train/\"\n","WEIGHT_PATH=\"/content/drive/MyDrive/CovidDetection/submission/yolov5/yolov5x.pt\"\n","IMG_SIZE = 256\n","BATCH_SIZE = 16\n","EPOCHS = 10\n","TEST_PATH = \"/content/drive/MyDrive/siim/tmp/test\"\n","BEST_MODEL_PATH  =\"/content/drive/MyDrive/siim/version3/yolov5/version3/exp/weights/best.pt\"\n","YAML_PATH=\"/content/drive/MyDrive/CovidDetection/submission/src/yolo.yaml\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQ48y-9HG5JZ"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov5/train.py --img {IMG_SIZE} \\\n","                 --batch {BATCH_SIZE} \\\n","                 --epochs {EPOCHS} \\\n","                 --data {YAML_PATH} \\\n","                 --weights {WIGHT_PATH} \\\n","                 --save_period 1\\\n","                 --project submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1bdMM5HzG7v3"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov5/detect.py --weights {BEST_MODEL_PATH} \\\n","                  --source {TEST_PATH} \\\n","                  --img 256 \\\n","                  --conf 0.281 \\\n","                  --iou-thres 0.5 \\\n","                  --max-det 3 \\\n","                  --save-txt \\\n","                  --save-conf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vEaBTbuYHGeC"},"source":["## Part 2-4 Exp 4\n","Fuzzy Logic+Yolov5s"]},{"cell_type":"markdown","metadata":{"id":"hLKhnAe7HYQ4"},"source":["### Part 2-4-1 Fuzzy logic: feature extraction"]},{"cell_type":"code","metadata":{"id":"KKhU3YfSHZHj"},"source":["import cv2\n","import math\n","import tqdm.notebook as tq\n","import numpy as np\n","import pandas as pd\n","import operator as op\n","from functools import reduce\n","from scipy.interpolate import interp1d\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"djaWf-hBHjtR"},"source":["epsilon = 0.00001\n","n=2\n","m=2\n","gamma=4\n","img_name = '0a0bb7af0cab'\n","test_folder = '/content/drive/MyDrive/siim/'\n","dir=\"/content/drive/MyDrive/siim/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LxYmwAHHoSE"},"source":["def add(epsilon , x1, x2):\n","    return (x1 + x2) / (1 + (x1 * x2) + epsilon)\n","\n","def subtract(epsilon ,x1, x2):\n","    return (x1 - x2) / (1 - (x1 * x2) + epsilon)\n","\n","def mult(epsilon, lamda, x):\n","    nom = ((1 + x) ** lamda) - ((1 - x) ** lamda)\n","    denom = ((1 + x) ** lamda) + ((1 - x) ** lamda)\n","    return nom / (denom+epsilon )\n","\n","def fai(epsilon ,x):\n","    return 0.5 * np.log((1 + x) / (1 - x + epsilon) )\n","\n","def norm(epsilon ,x):\n","    return np.abs(fai(epsilon,x))\n","\n","def comb(n, r):\n","    r = min(r, n - r)\n","    numer = reduce(op.mul, range(n, n - r, -1), 1)\n","    denom = reduce(op.mul, range(1, r + 1), 1)\n","    return numer / denom\n","\n","def colorAdd(q1,q2):\n","    res = []\n","    res.append(add(epsilon, q1[0] , q2[0]))\n","    res.append(add(epsilon, q1[1] , q2[1]))\n","    res.append(add(epsilon, q1[2] , q2[2]))\n","    return res\n","\n","\n","def colorSub(q1,q2):\n","    res = []\n","    res.append(subtract(epsilon, q1[0] , q2[0]))\n","    res.append(subtract(epsilon, q1[1] , q2[1]))\n","    res.append(subtract(epsilon, q1[2] , q2[2]))\n","    return res\n","\n","def colorMult(lamda,q):\n","    res = []\n","    res.append(mult(epsilon, lamda, q[0]))\n","    res.append(mult(epsilon, lamda, q[1]))\n","    res.append(mult(epsilon, lamda, q[2]))\n","    return res\n","\n","def colorNorm(q):\n","    res = 0\n","    res += fai(epsilon, q[0])**2\n","    res += fai(epsilon, q[1])**2\n","    res += fai(epsilon, q[2])**2\n","    return np.sqrt(res)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bgo-TiZHpNk"},"source":["class ImageEnh:\n","    def __init__(self, image, n, m, gamma):\n","        self.image = image\n","        self.n = n\n","        self.m = m\n","        self.gamma = gamma\n","        self.pixelMemberships = np.full((n, m, image.shape[0], image.shape[1]), -1000 , dtype=np.float)\n","        self.windowsMean = np.full((n, m), -1000 ,dtype=np.float)\n","        self.windowsCard = np.full((n, m), -1000 , dtype=np.float)\n","        self.pijMat = np.full((n, m, image.shape[0], image.shape[1]), -1000,dtype=np.float)\n","        self.windowsVariance = np.full((n, m), -1000,dtype=np.float)\n","        self.image = self.convertImgDown(self.image)\n","\n","    def convertImgDown(self, image):\n","        mapping = interp1d([0, 255], [-1, 1])\n","        image = mapping(image)\n","        #         for x in range(self.image.shape[0]):\n","        #             for y in range(self.image.shape[1]):\n","        #                 self.image[x][y] = (((self.image[x][y]) * (2)) / (255)) - 1\n","        return image\n","\n","    def convertImgUp(self, img):\n","        num1 = np.abs(np.min(img))\n","        num2 = np.abs(np.max(img))\n","        mapping = interp1d([-1*max(num1,num2), max(num1,num2)], [0, 255])\n","        img = mapping(img)\n","        #         new_img = np.zeros((self.image.shape[0] , self.image.shape[1]))\n","        #         for x in range(self.image.shape[0]):\n","        #             for y in range(self.image.shape[1]):\n","        #                 new_img[x][y] = (((img[x][y] + 1) * (255)) / (2))\n","        return img\n","\n","    def qxi(self, i, x):\n","        x0 = 0\n","        x1 = self.image.shape[0]\n","        nCi = comb(self.n, i)\n","        nom = ((x - x0) ** i) * ((x1 - x) ** (self.n - i))\n","        denom = (x1 - x0) ** self.n\n","        ans = nCi * nom / denom\n","        # if ans > 1 or ans < 0:\n","        #     print('Error in qxi : ', ans)\n","        return ans\n","\n","    def qyj(self, j, y):\n","        y0 = 0\n","        y1 = self.image.shape[1]\n","        nCi = comb(self.m, j)\n","        nom = (np.power((y - y0),j)) * (np.power((y1 - y) , (self.m - j)))\n","        denom = (y1 - y0) ** self.m\n","        ans = nCi * nom / denom\n","        # if ans > 1 or ans < 0:\n","        #     print('Error in qyj : ', ans)\n","        return ans\n","\n","    def pij(self, i, j, x, y):\n","        if self.pijMat[i][j][x][y] == -1000:\n","            ans = self.qxi(i, x) * self.qyj(j, y)\n","            # if ans > 1 or ans < 0:\n","            #     print('Error in pij : ', i, j, ans)\n","            self.pijMat[i][j][x][y] = ans\n","        return self.pijMat[i][j][x][y]\n","\n","    def membership(self, i, j, x, y):\n","        if self.pixelMemberships[i][j][x][y] == -1000:\n","            nom = self.pij(i, j, x, y) ** self.gamma\n","            denom = 0\n","            for idx1 in range(self.n):\n","                for idx2 in range(self.m):\n","                    denom += np.power(self.pij(idx1, idx2, x, y), self.gamma)\n","            ans = nom / (denom + epsilon)\n","            if ans > 1 or ans < 0 or math.isnan(ans):\n","                print('Error in membership : ', denom)\n","            self.pixelMemberships[i][j][x][y] = ans\n","        return self.pixelMemberships[i][j][x][y]\n","\n","    def windowCard(self, i, j):\n","        if self.windowsCard[i][j] == -1000:\n","            card = 0.0\n","            for x in range(self.image.shape[0]):\n","                for y in range(self.image.shape[1]):\n","                    card += self.membership(i, j, x, y)\n","            self.windowsCard[i][j] = card\n","        return self.windowsCard[i][j]\n","\n","    def windowMean(self, i, j):\n","        if self.windowsMean[i][j] == -1000:\n","            card = self.windowCard(i, j)\n","            mean = 0.0\n","            for x in range(self.image.shape[0]):\n","                for y in range(self.image.shape[1]):\n","                    mean = add(epsilon, mean, mult(epsilon, self.membership(i, j, x, y) / card, self.image[x][y]))\n","            self.windowsMean[i][j] = mean\n","        return self.windowsMean[i][j]\n","\n","    def windowVar(self, i, j):\n","        if self.windowsVariance[i][j] == -1000:\n","            var = 0.0\n","            card = self.windowCard(i, j)\n","            mean = self.windowMean(i, j)\n","            for x in range(self.image.shape[0]):\n","                for y in range(self.image.shape[1]):\n","                    memship = self.membership(i, j, x, y)\n","                    nom = memship * (norm(epsilon, subtract(epsilon, self.image[x][y], mean)) ** 2)\n","                    denom = card\n","                    var += nom / denom\n","            self.windowsVariance[i][j] = var\n","        return self.windowsVariance[i][j]\n","\n","    def enhanceImage(self):\n","        image_copy = np.zeros((self.image.shape[0], self.image.shape[1]))\n","        sigma = np.sqrt(1/3)\n","        for i in range(self.n):\n","            for j in range(self.m):\n","                mean = self.windowMean(i, j)\n","                variance = np.sqrt(self.windowVar(i, j))\n","                for x in range(self.image.shape[0]):\n","                    for y in range(self.image.shape[1]):\n","                        left = sigma / variance\n","                        psi = mult(epsilon, left, subtract(epsilon,self.image[x][y], mean))\n","                        memship = self.membership(i, j, x, y)\n","                        image_copy[x][y] += mult(epsilon, memship, psi)\n","        image_copy = self.convertImgUp(image_copy)\n","        return image_copy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoyT1ybrH8Pt"},"source":["class ColoredImageEnh:\n","    def __init__(self, image, n, m, gamma):\n","        \"\"\"\n","        Initializing the model and it's variables\n","        :param image: image to be enhanced\n","        :param n: number of windows in width\n","        :param m: number of windows in height\n","        :param gamma: fuzzification coffecient\n","        \"\"\"\n","        self.image = image\n","        self.n = n\n","        self.m = m\n","        self.gamma = gamma\n","\n","        # Membership matrix of pixels to each window\n","        self.pixelMemberships = np.full((n, m, image.shape[0], image.shape[1]), -1000, dtype=np.float)\n","        # Mean of each window\n","        self.windowsMean = np.full((n, m), -1000, dtype=np.float)\n","        # Cardinality of each window\n","        self.windowsCard = np.full((n, m), -1000, dtype=np.float)\n","        self.pijMat = np.full((n, m, image.shape[0], image.shape[1]), -1000, dtype=np.float)\n","        # Variance of each window\n","        self.windowsVariance = np.full((n, m), -1000, dtype=np.float)\n","\n","        self.image = self.convertImgDown(self.image)\n","\n","        # Luminosity matrix of colored image\n","        self.lum = np.full((image.shape[0] , image.shape[1]) , -1000 , dtype=np.float)\n","\n","    def convertImgDown(self, image):\n","        \"\"\"\n","        Mapping pixel values from interval [0 , 255] to [-1 , 1]\n","        :param image: image needed to be converted\n","        :return: image after mapping it to interval [-1 , 1]\n","        \"\"\"\n","        mapping = interp1d([0, 255], [-1, 1])\n","        image = mapping(image)\n","        return image\n","\n","    def convertImgUp(self, img):\n","        \"\"\"\n","        Mapping pixel values from interval [-1 , 1] to interval [0 , 255]\n","        :param img: image needed to be converted\n","        :return: image after mapping\n","        \"\"\"\n","        mapping = interp1d([np.min(img), np.max(img)], [0, 255])\n","        img = mapping(img)\n","        return img\n","\n","    def imageLuminosity(self,i,j):\n","        \"\"\"\n","        Calculating the Luminosity of colored image at index i , j\n","        :param i: row index\n","        :param j: column index\n","        :return: The luminosity value at index [i j]\n","        \"\"\"\n","        if self.lum[i][j] == -1000:\n","            for x in range(self.image.shape[0]):\n","                for y in range(self.image.shape[1]):\n","                    temp = add(epsilon, self.image[x][y][2] , self.image[x][y][1])\n","                    temp = add(epsilon, temp , self.image[x][y][0])\n","                    self.lum[x][y] = mult(epsilon, 1/3 , temp)\n","        return self.lum[i][j]\n","\n","\n","    def qxi(self, i, x):\n","        \"\"\"\n","        Calculating formula:\n","        :param i:\n","        :param x:\n","        :return:\n","        \"\"\"\n","        x0 = 0\n","        x1 = self.image.shape[0]\n","        nCi = comb(self.n, i)\n","        nom = ((x - x0) ** i) * ((x1 - x) ** (self.n - i))\n","        denom = (x1 - x0) ** self.n\n","        ans = nCi * nom / denom\n","        return ans\n","\n","    def qyj(self, j, y):\n","        y0 = 0\n","        y1 = self.image.shape[1]\n","        nCi = comb(self.m, j)\n","        nom = (np.power((y - y0), j)) * (np.power((y1 - y), (self.m - j)))\n","        denom = (y1 - y0) ** self.m\n","        ans = nCi * nom / denom\n","        return ans\n","\n","    def pij(self, i, j, x, y):\n","        if self.pijMat[i][j][x][y] == -1000:\n","            ans = self.qxi(i, x) * self.qyj(j, y)\n","            self.pijMat[i][j][x][y] = ans\n","        return self.pijMat[i][j][x][y]\n","\n","    def membership(self, i, j, x, y):\n","        \"\"\"\n","        Calculating the membership of pixel [x][y] to a window i,j\n","        :param i: window row index\n","        :param j: window column index\n","        :param x: pixel row index\n","        :param y: pixel column index\n","        :return: Membership value\n","        \"\"\"\n","        if self.pixelMemberships[i][j][x][y] == -1000:\n","            nom = self.pij(i, j, x, y) ** self.gamma\n","            denom = 0\n","            for idx1 in range(self.n):\n","                for idx2 in range(self.m):\n","                    denom += np.power(self.pij(idx1, idx2, x, y), self.gamma)\n","            ans = nom / (denom + epsilon)\n","            self.pixelMemberships[i][j][x][y] = ans\n","        return self.pixelMemberships[i][j][x][y]\n","\n","    def windowCard(self, i, j):\n","        \"\"\"\n","        Calculating the cardinality of window i,j\n","        :param i:\n","        :param j:\n","        :return: window card value\n","        \"\"\"\n","        if self.windowsCard[i][j] == -1000:\n","            card = 0.0\n","            for x in range(self.image.shape[0]):\n","                for y in range(self.image.shape[1]):\n","                    card += self.membership(i, j, x, y)\n","            self.windowsCard[i][j] = card\n","        return self.windowsCard[i][j]\n","\n","    def windowMean(self, i, j):\n","        \"\"\"\n","        Calculating the mean of window i,j\n","        :param i:\n","        :param j:\n","        :return: Mean value\n","        \"\"\"\n","        if self.windowsMean[i][j] == -1000:\n","            card = self.windowCard(i, j)\n","            mean = 0.0\n","            for x in range(self.image.shape[0]):\n","                for y in range(self.image.shape[1]):\n","                    mean = add(epsilon, mean, mult(epsilon, self.membership(i, j, x, y) / card, self.imageLuminosity(x,y)))\n","            self.windowsMean[i][j] = mean\n","        return self.windowsMean[i][j]\n","\n","    def windowVar(self, i, j):\n","        \"\"\"\n","        Calculating the squared Variance of a window\n","        :param i:\n","        :param j:\n","        :return: Squared variance value\n","        \"\"\"\n","        if self.windowsVariance[i][j] == -1000:\n","            var = 0.0\n","            card = self.windowCard(i, j)\n","            mean = self.windowMean(i, j)\n","            for x in range(self.image.shape[0]):\n","                for y in range(self.image.shape[1]):\n","                    memship = self.membership(i, j, x, y)\n","                    nom = memship * (norm(epsilon, subtract(epsilon, self.imageLuminosity(x,y), mean)) ** 2)\n","                    denom = card\n","                    var += nom / denom\n","            self.windowsVariance[i][j] = var\n","        return self.windowsVariance[i][j]\n","\n","    def imageEnhance(self):\n","        \"\"\"\n","        Iterating over the channels , pixel and windows and calculate the new image after enhancing\n","        :return: Enhanced image after converting it to interval[0,255]\n","        \"\"\"\n","        final_img = np.zeros((self.image.shape[0] , self.image.shape[1] , 3) , dtype=np.float)\n","        sigma = np.sqrt(1/3)\n","        for chn in range(3):\n","            for i in range(self.n):\n","                for j in range(self.m):\n","                    var = np.sqrt(self.windowVar(i,j))\n","                    mean = self.windowMean(i,j)\n","                    for x in range(self.image.shape[0]):\n","                        for y in range(self.image.shape[1]):\n","                            memship = self.membership(i, j, x, y)\n","                            final_img[x][y][chn] += mult(epsilon, (memship*sigma/var) , subtract(epsilon, self.image[x][y][chn] , mean))\n","\n","        final_img = self.convertImgUp(final_img)\n","\n","        return final_img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sXKdqpbIA5l"},"source":["def colored_enhancing(filepath, gray_tarpath):\n","    img = cv2.imread(filepath)\n","    #print(img.shape)\n","    imgEnh = ColoredImageEnh(img, n, m, gamma)\n","    final_image = imgEnh.imageEnhance()\n","    final_image = np.array(final_image, dtype=np.uint8)\n","    #cv2_imshow(img)\n","    #cv2_imshow(final_image)\n","    #cv2.imshow('before converting', img)\n","    #cv2.imshow('final', final_image)\n","    cv2.imwrite(gray_tarpath, final_image)\n","    #print(final_image)\n","    #cv2.waitKey(1)\n","    #cv2.destroyAllWindows()\n","\n","def gray_enhancing(filepath, colored_tarpath):\n","    img = cv2.imread(filepath)\n","    #print(img.shape)\n","    img = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n","    imgEnh = ImageEnh(img ,n,m,gamma)\n","    final_image = imgEnh.enhanceImage()\n","    final_image = np.array(final_image , dtype = np.uint8)\n","    #cv2_imshow(img)\n","    #cv2_imshow(final_image)\n","    #cv2_imshow('before converting' , img)\n","    #cv2_imshow('final' , final_image)\n","    cv2.imwrite(colored_tarpath, final_image)\n","    #cv2.waitKey(1)\n","    #cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TkKrwK1ZIMRO"},"source":["os.makedirs('/content/drive/MyDrive/CovidDetection/dataset/fgtmp/train', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/dataset/fgtmp/test', exist_ok=True)\n","\n","os.makedirs('/content/drive/MyDrive/CovidDetection/dataset/fctmp/train', exist_ok=True)\n","os.makedirs('/content/drive/MyDrive/CovidDetection/dataset/fctmp/test', exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wv4nEOyZIc22"},"source":["info.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XfEqh6rwIgG0"},"source":["# first time 893 seccess\n","# second time 1160 seccess\n","# third time 650 success\n","# forth time 761 success\n","# fifth time 382 success\n","# sixth time 91 success\n","# seventh time 996 success\n","# eighth time 987 success\n","# ninth time 416 success\n","for i in tq.tqdm(range(5918,info.shape[0])):\n","    row=info.iloc[i]\n","    filepath=row.filepath\n","    gray_tarpath=row.fgfp\n","    #print(gray_tarpath)\n","    colored_tarpath=row.fcfp\n","    #print(colored_tarpath)d\n","    gray_enhancing(filepath, gray_tarpath)\n","    colored_enhancing(filepath, colored_tarpath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DFvL6hYCImzW"},"source":["### Part 2-4-2 YOLOv5s\n","- Fuzzy colored images\n","- Fuzzy gray images"]},{"cell_type":"code","metadata":{"id":"RZEd4RBNItSL"},"source":["TRAIN_PATH = \"/content/drive/MyDrive/CovidDetection/dataset/tmp/train/\"\n","WEIGHT_PATH=\"/content/drive/MyDrive/CovidDetection/submission/yolov5/yolov5x.pt\"\n","IMG_SIZE = 256\n","BATCH_SIZE = 16\n","EPOCHS = 10\n","TEST_PATH = \"/content/drive/MyDrive/siim/tmp/test\"\n","BEST_MODEL_PATH  =\"/content/drive/MyDrive/siim/version3/yolov5/version3/exp/weights/best.pt\"\n","YAML_PATH=\"/content/drive/MyDrive/CovidDetection/submission/src/yolo.yaml\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ST3UpLHGI69y"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov5/train.py --img {IMG_SIZE} \\\n","                 --batch {BATCH_SIZE} \\\n","                 --epochs {EPOCHS} \\\n","                 --data {YAML_PATH} \\\n","                 --weights {WIGHT_PATH} \\\n","                 --save_period 1\\\n","                 --project submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_UIURiVI_th"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov5/detect.py --weights {BEST_MODEL_PATH} \\\n","                  --source {TEST_PATH} \\\n","                  --img 256 \\\n","                  --conf 0.281 \\\n","                  --iou-thres 0.5 \\\n","                  --max-det 3 \\\n","                  --save-txt \\\n","                  --save-conf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sScFnGMrJC8j"},"source":["TRAIN_PATH = \"/content/drive/MyDrive/CovidDetection/dataset/tmp/train/\"\n","WEIGHT_PATH=\"/content/drive/MyDrive/CovidDetection/submission/yolov5/yolov5x.pt\"\n","IMG_SIZE = 256\n","BATCH_SIZE = 16\n","EPOCHS = 10\n","TEST_PATH = \"/content/drive/MyDrive/siim/tmp/test\"\n","BEST_MODEL_PATH  =\"/content/drive/MyDrive/siim/version3/yolov5/version3/exp/weights/best.pt\"\n","YAML_PATH=\"/content/drive/MyDrive/CovidDetection/submission/src/yolo.yaml\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yp945HsiJP6g"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov5/train.py --img {IMG_SIZE} \\\n","                 --batch {BATCH_SIZE} \\\n","                 --epochs {EPOCHS} \\\n","                 --data {YAML_PATH} \\\n","                 --weights {WIGHT_PATH} \\\n","                 --save_period 1\\\n","                 --project submission"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxEUoKwWJSt8"},"source":["!python /content/drive/MyDrive/CovidDetection/submission/yolov5/detect.py --weights {BEST_MODEL_PATH} \\\n","                  --source {TEST_PATH} \\\n","                  --img 256 \\\n","                  --conf 0.281 \\\n","                  --iou-thres 0.5 \\\n","                  --max-det 3 \\\n","                  --save-txt \\\n","                  --save-conf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QYk_yXoIJVHJ"},"source":["## Part 2-5 Choquet Intergral"]},{"cell_type":"code","metadata":{"id":"H9H_nru0JvwE"},"source":["import torch\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8UB04yYvKUAW"},"source":["### Part 2-5-1 CHI NN\n","Unknown reason to crash the Google terminal\n","But the programme works well in my personal laptop, unfortunetely, I don't have GPU, so I can't support the last dl."]},{"cell_type":"code","metadata":{"id":"Zi5Xj9bzKYXL"},"source":["# Convert decimal to binary string\n","def sources_and_subsets_nodes(N):\n","  str1 = \"{0:{fill}\"+str(N)+\"b}\"\n","  a = []\n","  for i in range(1,2**N):\n","    a.append(str1.format(i, fill='0'))\n","\n","  sourcesInNode = []\n","  sourcesNotInNode = []\n","  subset = []\n","  sourceList = list(range(N))\n","\n","  # find subset nodes of a node\n","  def node_subset(node, sourcesInNodes):\n","    return [node - 2**(i) for i in sourcesInNodes]\n","\n","  # convert binary encoded string to integer list\n","  def string_to_integer_array(s, ch):\n","    N = len(s) \n","    return [(N - i - 1) for i, ltr in enumerate(s) if ltr == ch]\n","\n","  for j in range(len(a)):\n","  # index from right to left\n","    idxLR = string_to_integer_array(a[j],'1')\n","    sourcesInNode.append(idxLR)  \n","    sourcesNotInNode.append(list(set(sourceList) - set(idxLR)))\n","    subset.append(node_subset(j,idxLR))\n","\n","  print(\"sources_and_subsets_nodes\")\n","  return sourcesInNode, subset\n","\n","def subset_to_indices(indices):\n","  print(\"subset_to_indeces\")\n","  return [i for i in indices]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u645R87mKfdR"},"source":["class Choquet_integral(torch.nn.Module):\n","  def __init__(self, N_in, N_out):\n","    super(Choquet_integral,self).__init__()\n","    self.N_in = N_in\n","    self.N_out = N_out\n","    self.nVars = 2**self.N_in - 2\n","\n","    # The FM is initialized with mean\n","    dummy = (1./self.N_in) * torch.ones((self.nVars, self.N_out), requires_grad=True)\n","\n","    # self.vars = torch.nn.Parameter( torch.Tensor(self.nVars,N_out))\n","    self.vars = torch.nn.Parameter(dummy)\n","\n","    # following function uses numpy vs pytorch\n","    self.sourcesInNode, self.subset = sources_and_subsets_nodes(self.N_in)\n","    self.sourcesInNode = [torch.tensor(x) for x in self.sourcesInNode]\n","    self.subset = [torch.tensor(x) for x in self.subset]\n","    print(\"self.subset/n\",self.subset)\n","\n","  def forward(self,inputs):    \n","    self.FM = self.chi_nn_vars(self.vars)\n","    sortInputs, sortInd = torch.sort(inputs,1, True)\n","    M, N = inputs.size()\n","    sortInputs = torch.cat((sortInputs, torch.zeros(M,1)), 1)\n","    sortInputs = sortInputs[:,:-1] -  sortInputs[:,1:]\n","    out = torch.cumsum(torch.pow(2,sortInd),1) - torch.ones(1, dtype=torch.int64)\n","    data = torch.zeros((M,self.nVars+1))\n","    \n","    for i in range(M):\n","      data[i,out[i,:]] = sortInputs[i,:] \n","      ChI = torch.matmul(data,self.FM)\n","\n","    print(\"forward\")\n","    return ChI\n","\n","  # Converts NN-vars to FM vars\n","  def chi_nn_vars(self, chi_vars):\n","    # nVars,_ = chi_vars.size()\n","    chi_vars = torch.abs(chi_vars)\n","    # nInputs = inputs.get_shape().as_list()[1]\n","    FM = chi_vars[None, 0,:]\n","    \n","    for i in range(1,self.nVars):\n","      indices = subset_to_indices(self.subset[i])\n","      if (len(indices) == 1):\n","        FM = torch.cat((FM,chi_vars[None,i,:]),0)\n","      else:\n","      # ss=tf.gather_nd(variables, [[1],[2]])\n","        maxVal,_ = torch.max(FM[indices,:],0)\n","        temp = torch.add(maxVal,chi_vars[i,:])\n","    FM = torch.cat((FM,temp[None,:]),0)\n","    FM = torch.cat([FM, torch.ones((1,self.N_out))],0)\n","    FM = torch.min(FM, torch.ones(1))  \n","\n","    print(\"chi_nn_vars\")\n","    return FM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pncvifcvK2Ft"},"source":["# training samples size\n","M = 10\n","# number of inputs\n","N_in = 3\n","# number of outputs aka number of Choquet integral neurons\n","N_out = 2  \n","# Create a synthetic dataset via random sampling from a normal distribution with mean =-1 and std=2\n","X_train = np.random.rand(M,N_in)*2-1\n","# Let's specify the FMs  (There will be N_out number of FMs)\n","# Herein we adopt binary encoding instead of lexicographic encoding to represent a FM that is easier to code. \n","# As for example, an FM for three inputs using lexicographic encoding is, g = {g_1, g_2, g_3, g_{12}, g_{13}, g_{23}, g_{123}}.\n","# whereas its binary encoding is g = {g_1, g_2, g_{12}, g_3 g_{13}, g_{23}, g_{123}}.\n","# For simplicity, here we use OWA. \n","print(X_train)\n","OWA = np.array([[0.7, 0.2, 0.1], # this is soft-max\n","                    [0.1,0.2,0.7]])  # soft-min\n","# The FMs of the above OWAs in binary encoding\n","# FM = [[0.7, 0.7, 0.9, 0.7, 0.9, 0.9, 1.0].\n","#      [0.1, 0.1, 0.3, 0.1, 0.3, 0.3, 1.0]]\n","print('Actual/groundtruth FMs in binary encoding:')\n","print('FM1 = ', np.array([0.7, 0.7, 0.9, 0.7, 0.9, 0.9, 1.0]))\n","print('FM2 = ', np.array([0.1, 0.1, 0.3, 0.1, 0.3, 0.3, 1.0]))\n","\n","# Generate the label or the groundtruth based on the provided FMs/OWAs. The labels are two dimentional\n","label_train = np.matmul(np.sort(X_train), np.fliplr(OWA).T)\n","    \n","# Now we want to recover the FMs from the training data and groundtruth\n","# First, build a Choquet integral neuron with N_in inputs and N_out outputs\n","net = Choquet_integral(N_in,N_out)\n","    \n","# set the optimization algorithms and paramters the learning\n","learning_rate = 0.3;\n","    \n","# Construct our loss function and an Optimizer. The call to model.parameters()\n","# in the SGD constructor will contain the learnable parameters of the two\n","# nn.Linear modules which are members of the model.\n","criterion = torch.nn.MSELoss(reduction='mean')\n","optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)   \n","    \n","num_epochs = 300;\n","    \n","# convert from numpy to torch tensor\n","X_train = torch.tensor(X_train,dtype=torch.float) #.to(\"cuda\")\n","label_train = torch.tensor(label_train,dtype=torch.float) #.to(\"cuda\")\n","\n","model.train()\n","# optimize\n","for t in range(num_epochs):\n","# Forward pass: Compute predicted y by passing x to the model\n","\n","## Terminal crashed here! Tensor is not transfered into GPU?! But to(\"cuda\") doesn't work.\n","  y_pred = net(X_train)\n","\n","# Compute the loss\n","  loss = criterion(y_pred, label_train)\n","# Zero gradients, perform a backward pass, and update the weights.\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n","\n","# Finally, the learned FMs\n","FM_learned = (net.chi_nn_vars(net.vars).cpu()).detach().numpy()\n","print('\\n\\nLearned FMs:')\n","print('FM1 = ', FM_learned[:,0])\n","print('FM2 = ',FM_learned[:,1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_FCw0Dg3KrCU"},"source":["### Part 2-5-2 CHI"]},{"cell_type":"code","metadata":{"id":"Obezqfw2Kw0f"},"source":["def _differentiation_1_distance(X):\n","    #Perform differentiation for each consecuent point in the X dataset (time series)\n","    print(\"dis:\")\n","    print(X[0], X[1:] - X[0:-1])\n","    return np.append(X[0], X[1:] - X[0:-1])\n","\n","\n","def generate_cardinality(N, p = 2):\n","    '''\n","    Generate the cardinality measure for a N-sized vector.\n","    '''\n","    print(\"FM:\")\n","    for x in np.arange(N, 0, -1):\n","      print((x/ N)**p) \n","    return [(x/ N)**p for x in np.arange(N, 0, -1)]\n","\n","\n","def generate_cardinality_matrix(N, matrix_shape, p = 2):\n","    '''\n","    Generate the cardinality measure for a N-sized vector, and returns it in a matrix shape.\n","    Use this if you cannot broadcast generate_cardinality() correctly.\n","    N and matrix_shape must be coherent (matrix_shape[0] == N)\n","    '''\n","    res = np.zeros(matrix_shape)\n","    dif_elements = [(x/ N)**p for x in np.arange(N, 0, -1)]\n","\n","    for ix, elements in enumerate(dif_elements ):\n","        res[ix,...] = dif_elements[ix]\n","\n","    return res\n","\n","\n","def choquet_integral_symmetric(X, measure=None, axis=0, keepdims=True):\n","    '''\n","    Aggregates a numpy array alongise an axis using the choquet integral.\n","    \n","    :param X: Data to aggregate.\n","    :param measure: Vector containing the measure numeric values (Symmetric!)\n","    :param axis: Axis alongside to aggregate.\n","    '''\n","    if measure is None:\n","        measure = generate_cardinality(\n","            X.shape[axis])\n","\n","    X_sorted = np.sort(X, axis = axis)\n","\n","    X_differenced = np.apply_along_axis(\n","    _differentiation_1_distance, axis, X_sorted)\n","    X_agg  = np.apply_along_axis(lambda a: np.dot(a, measure), axis, X_differenced)\n","\n","    if keepdims:\n","        X_agg = np.expand_dims(X_agg, axis=axis)\n","\n","    return X_agg\n","\n","\n","\n","def sugeno_fuzzy_integral(X, measure=None, axis = 0, keepdims=True):\n","    '''\n","    Aggregates data using a generalization of the Choquet integral.\n","    \n","    :param X: Data to aggregate.\n","    :param measure: Vector containing the measure numeric values.\n","    :param axis: Axis alongside to aggregate.\n","    '''\n","    if measure is None:\n","        measure = generate_cardinality(\n","                X.shape[axis])\n","\n","    return sugeno_fuzzy_integral_generalized(X, measure, axis, np.minimum, np.amax, keepdims)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlk1Q2e5Lvw6"},"source":["choquet_integral_symmetric(np.array([0.2,0.9,0.8]))\n","sugeno_fuzzy_integral(np.array([0.2,0.9,0.8]))"],"execution_count":null,"outputs":[]}]}